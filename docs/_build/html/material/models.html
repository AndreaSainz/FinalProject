

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Model Architectures and Training Base &mdash; ct_reconstruction 0.1.0-beta documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/sg_gallery.css?v=61a4c737" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=c903bf51"></script>
      <script src="../_static/doctools.js?v=9a2dae69"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
      <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Utility Functions for CT Reconstruction" href="utils.html" />
    <link rel="prev" title="LoDoPaBDataset Class" href="datasets.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            ct_reconstruction
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">API Reference</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="datasets.html">LoDoPaBDataset Class</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Model Architectures and Training Base</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#how-to-import">How to Import:</a></li>
<li class="toctree-l2"><a class="reference internal" href="#module-ct_reconstruction.models.model">API Reference:</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="utils.html">Utility Functions for CT Reconstruction</a></li>
<li class="toctree-l1"><a class="reference internal" href="callbacks.html">EarlyStopping Callback</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">ct_reconstruction</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Model Architectures and Training Base</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/material/models.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="model-architectures-and-training-base">
<h1>Model Architectures and Training Base<a class="headerlink" href="#model-architectures-and-training-base" title="Link to this heading"></a></h1>
<p>This module includes the core model architecture and the base class for training deep learning models for CT reconstruction.</p>
<p>Included components:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">ModelBase</span></code>: A reusable base class that handles training, validation, testing, and metric logging.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DBP</span></code>: Deep Back Projection model for CT image reconstruction.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DeepFBP</span></code>: Deep Filtered Back Projection model for CT image reconstruction.</p></li>
</ul>
<section id="how-to-import">
<h2>How to Import:<a class="headerlink" href="#how-to-import" title="Link to this heading"></a></h2>
<p>After installing the <cite>ct_reconstruction</cite> package, you can import the models as:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">ct_reconstruction.models.model</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelBase</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ct_reconstruction.models.deep_back_projection</span><span class="w"> </span><span class="kn">import</span> <span class="n">DBP</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">ct_reconstruction.models.deep_filtered_back_projection</span><span class="w"> </span><span class="kn">import</span> <span class="n">DeepFBP</span>
</pre></div>
</div>
</section>
<section id="module-ct_reconstruction.models.model">
<span id="api-reference"></span><h2>API Reference:<a class="headerlink" href="#module-ct_reconstruction.models.model" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="ct_reconstruction.models.model.ModelBase">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ct_reconstruction.models.model.</span></span><span class="sig-name descname"><span class="pre">ModelBase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">model_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">single_bp</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_single_BP</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">i_0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">optimizer_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accelerator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_file</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">'training.log'</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.model.ModelBase" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Abstract base class for CT reconstruction training, evaluation, and analysis.</p>
<p>This class establishes a consistent interface and behavior for CT models by:
- Defining projection and volume geometries using the Tomosipo library.
- Loading and preprocessing CT datasets (LoDoPaB-style).
- Handling training loops, validation with metrics (PSNR, SSIM), and early stopping.
- Providing visualization and logging of training/testing progress.
- Supporting classical CT reconstruction algorithms (e.g., FBP, SIRT, EM, TV-Min, NAG-LS).</p>
<p>This class is intended to be subclassed with a defined model in <cite>self.model</cite>.</p>
<dl>
<dt>Attributes:</dt><dd><p>model_path (str): Output path for checkpoints, logs, and metrics.
model_type (str): Identifier for the model architecture.
n_single_BP (int): Number of backprojections per sample.
alpha (float): Normalization constant for PSNR.
i_0 (float): Incident X-ray intensity used in noise simulation.
sigma (float): Standard deviation of Gaussian noise.
batch_size (int): Training and validation batch size.
epochs (int): Maximum number of training epochs.
optimizer_type (str): Optimizer type, e.g., ‘Adam’.
loss_type (str): Loss function name, e.g., ‘MSELoss’.
learning_rate (float): Initial learning rate.
debug (bool): Enables debug-level logging.
seed (int): Seed for reproducibility.
scheduler (bool): Enables learning rate scheduling.
accelerator (Accelerator): accelerate.Accelerator instance for distributed training.</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">accelerate</span><span class="w"> </span><span class="kn">import</span> <span class="n">Accelerator</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">MyModel</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">model_path</span><span class="o">=</span><span class="s1">&#39;checkpoints/my_model&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">model_type</span><span class="o">=</span><span class="s1">&#39;UNet&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">single_bp</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_single_BP</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">i_0</span><span class="o">=</span><span class="mf">1e5</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">sigma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">optimizer_type</span><span class="o">=</span><span class="s1">&#39;AdamW&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">loss_type</span><span class="o">=</span><span class="s1">&#39;MSELoss&#39;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-4</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">debug</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">123</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">accelerator</span><span class="o">=</span><span class="n">Accelerator</span><span class="p">(),</span>
<span class="gp">... </span>    <span class="n">scheduler</span><span class="o">=</span><span class="kc">True</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="s2">&quot;data/train&quot;</span><span class="p">,</span> <span class="s2">&quot;data/val&quot;</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s2">&quot;outputs/recon&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="s2">&quot;data/test&quot;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">results</span><span class="p">(</span><span class="s2">&quot;both&quot;</span><span class="p">,</span> <span class="n">example_number</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s2">&quot;outputs/plots&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.model.ModelBase.evaluate">
<span class="sig-name descname"><span class="pre">evaluate</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test_dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mse_fn</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.model.ModelBase.evaluate" title="Link to this definition"></a></dt>
<dd><p>Evaluates the model on a test set with performance metrics.</p>
<p>Computes the total test loss, PSNR, and SSIM. Also returns raw prediction,
ground truth, and sinogram tensors for downstream visualization or analysis.</p>
<dl>
<dt>Args:</dt><dd><p>test_dataloader (DataLoader): DataLoader with test samples.
loss (nn.Module): Loss function to compute evaluation error.
mse_fn (nn.Module or None): MSE loss for PSNR (if needed).</p>
</dd>
<dt>Returns:</dt><dd><p>tuple: (predictions, ground_truths, sinograms, total_loss, total_psnr, total_ssim)</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">preds</span><span class="p">,</span> <span class="n">gts</span><span class="p">,</span> <span class="n">sinos</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="n">psnr</span><span class="p">,</span> <span class="n">ssim</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">evaluate</span><span class="p">(</span><span class="n">test_loader</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">mse_fn</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.model.ModelBase.load_model">
<span class="sig-name descname"><span class="pre">load_model</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.model.ModelBase.load_model" title="Link to this definition"></a></dt>
<dd><p>Loads a pretrained model checkpoint from file.</p>
<p>Restores model weights and sets the trained flag. Supports custom or default path.</p>
<dl>
<dt>Args:</dt><dd><p>path (str, optional): Path to model checkpoint. Defaults to <cite>self.model_path</cite>.</p>
</dd>
<dt>Raises:</dt><dd><p>FileNotFoundError: If checkpoint does not exist.
ValueError: If <cite>self.model</cite> is not initialized.</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">load_model</span><span class="p">(</span><span class="s2">&quot;checkpoints/unet_model.pt&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.model.ModelBase.other_ct_reconstruction">
<span class="sig-name descname"><span class="pre">other_ct_reconstruction</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">sinogram</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iterations_sirt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iterations_em</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iterations_tv_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iterations_nag_ls</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lamda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.model.ModelBase.other_ct_reconstruction" title="Link to this definition"></a></dt>
<dd><p>Visualizes training and/or testing results with optional plots and image comparisons.</p>
<p>Generates performance plots (Loss, PSNR, SSIM) over training epochs, and optionally
displays side-by-side image comparisons of predictions vs. ground truth on test data.</p>
<dl>
<dt>Args:</dt><dd><p>mode (str): One of [‘training’, ‘testing’, ‘both’] to specify what to plot.
example_number (int): Number of test examples to visualize (for ‘testing’ mode).
save_path (str, optional): Base path for saving generated plot images.</p>
</dd>
<dt>Returns:</dt><dd><p>list[int] or None: List of visualized test sample indices if <cite>mode=’testing’</cite>.</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">results</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;training&#39;</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s1">&#39;outputs/train&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">results</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;testing&#39;</span><span class="p">,</span> <span class="n">example_number</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">results</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s1">&#39;outputs/combined&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.model.ModelBase.report_results_images">
<span class="sig-name descname"><span class="pre">report_results_images</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">samples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iterations_sirt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iterations_em</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iterations_tv_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iterations_nag_ls</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lamda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.model.ModelBase.report_results_images" title="Link to this definition"></a></dt>
<dd><p>Generates image-based visual comparison of model predictions and classical methods.</p>
<p>Each sample includes:
- Ground truth image
- Model prediction
- Classical reconstructions (FBP, SIRT, EM, TV-Min, NAG-LS)</p>
<dl>
<dt>Args:</dt><dd><p>save_path (str): Output prefix for saving figures.
samples (list[int]): Indices of test samples to visualize.
num_iterations_sirt (int): Iterations for SIRT.
num_iterations_em (int): Iterations for EM.
num_iterations_tv_min (int): Iterations for TV minimization.
num_iterations_nag_ls (int): Iterations for NAG-LS.
lamda (float): Regularization weight for TV minimization.</p>
</dd>
<dt>Raises:</dt><dd><p>RuntimeError: If required .pt files are missing.</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">report_results_images</span><span class="p">(</span><span class="s1">&#39;out/images&#39;</span><span class="p">,</span> <span class="n">samples</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mi">12</span><span class="p">])</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.model.ModelBase.report_results_table">
<span class="sig-name descname"><span class="pre">report_results_table</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">save_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">test_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_len_test</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iterations_sirt</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iterations_em</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iterations_tv_min</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_iterations_nag_ls</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">100</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">lamda</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.0001</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">only_results</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.model.ModelBase.report_results_table" title="Link to this definition"></a></dt>
<dd><p>Computes and saves average PSNR/SSIM for classical reconstruction methods on test data.</p>
<p>If <cite>only_results=True</cite>, computes metrics from raw test inputs without relying on saved
prediction files. Otherwise, loads previously saved .pt files for evaluation.</p>
<dl>
<dt>Args:</dt><dd><p>save_path (str): Path prefix to store CSV file.
test_path (str): Path to the test dataset (required if only_results=True).
max_len_test (int): Number of test samples (required if only_results=True).
num_iterations_sirt (int): Iterations for SIRT.
num_iterations_em (int): Iterations for EM.
num_iterations_tv_min (int): Iterations for TV minimization.
num_iterations_nag_ls (int): Iterations for NAG-LS.
lamda (float): Regularization weight for TV.
only_results (bool): If True, recompute from raw data.</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">report_results_table</span><span class="p">(</span><span class="s1">&#39;results/classical&#39;</span><span class="p">,</span> <span class="n">test_path</span><span class="o">=</span><span class="s1">&#39;data/test&#39;</span><span class="p">,</span> <span class="n">max_len_test</span><span class="o">=</span><span class="mi">256</span><span class="p">,</span> <span class="n">only_results</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.model.ModelBase.results">
<span class="sig-name descname"><span class="pre">results</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">mode</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">example_number</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.model.ModelBase.results" title="Link to this definition"></a></dt>
<dd><p>Visualizes training and/or testing results with optional plots and image comparisons.</p>
<p>Generates performance plots (Loss, PSNR, SSIM) over training epochs, and optionally
displays side-by-side image comparisons of predictions vs. ground truth on test data.</p>
<dl>
<dt>Args:</dt><dd><p>mode (str): One of [‘training’, ‘testing’, ‘both’] to specify what to plot.
example_number (int): Number of test examples to visualize (for ‘testing’ mode).
save_path (str, optional): Base path for saving generated plot images.</p>
</dd>
<dt>Returns:</dt><dd><p>list[int] or None: List of visualized test sample indices if <cite>mode=’testing’</cite>.</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">results</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;training&#39;</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s1">&#39;outputs/train&#39;</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">results</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;testing&#39;</span><span class="p">,</span> <span class="n">example_number</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">results</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s1">&#39;both&#39;</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s1">&#39;outputs/combined&#39;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.model.ModelBase.setup_optimizer_and_loss">
<span class="sig-name descname"><span class="pre">setup_optimizer_and_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.model.ModelBase.setup_optimizer_and_loss" title="Link to this definition"></a></dt>
<dd><p>Initializes the optimizer and loss function for training.</p>
<p>This method configures the optimizer and loss function based on the values 
specified in <cite>self.optimizer_type</cite> and <cite>self.loss_type</cite>. Only model parameters 
with <cite>requires_grad=True</cite> are passed to the optimizer.</p>
<dl>
<dt>Supported optimizers:</dt><dd><ul class="simple">
<li><p>“Adam”</p></li>
<li><p>“AdamW”</p></li>
</ul>
</dd>
<dt>Supported loss functions:</dt><dd><ul class="simple">
<li><p>“MSELoss”</p></li>
<li><p>“L1Loss”</p></li>
</ul>
</dd>
<dt>Args:</dt><dd><dl class="simple">
<dt>learning_rate (float, optional): Learning rate to use. If not provided, </dt><dd><p>uses <cite>self.learning_rate</cite>.</p>
</dd>
</dl>
</dd>
<dt>Raises:</dt><dd><p>ValueError: If an unsupported optimizer or loss type is provided.</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">optimizer_type</span> <span class="o">=</span> <span class="s2">&quot;Adam&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">loss_type</span> <span class="o">=</span> <span class="s2">&quot;MSELoss&quot;</span>
<span class="gp">&gt;&gt;&gt; </span><span class="bp">self</span><span class="o">.</span><span class="n">setup_optimizer_and_loss</span><span class="p">(</span><span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.model.ModelBase.test">
<span class="sig-name descname"><span class="pre">test</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">test_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_len_test</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.model.ModelBase.test" title="Link to this definition"></a></dt>
<dd><p>Tests the trained model on a separate dataset.</p>
<p>This method loads test samples, computes predictions, saves results to disk,
and logs PSNR/SSIM scores. It uses the same loss function used during training.</p>
<dl>
<dt>Args:</dt><dd><p>test_path (str): Path to test dataset.
max_len_test (int, optional): Max number of test samples.</p>
</dd>
<dt>Returns:</dt><dd><p>dict: Dictionary with test loss, PSNR, and SSIM.</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">results</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">test</span><span class="p">(</span><span class="s2">&quot;data/test&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.model.ModelBase.train">
<span class="sig-name descname"><span class="pre">train</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_len_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_len_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confirm_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_examples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">number_of_examples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.model.ModelBase.train" title="Link to this definition"></a></dt>
<dd><p>Trains the model with early stopping and optional learning rate scheduling.</p>
<p>Includes model summary, optimizer/loss setup, training/validation loops,
and metrics logging. Also supports checkpointing and visualization.</p>
<dl>
<dt>Args:</dt><dd><p>training_path (str): Path to training dataset.
validation_path (str): Path to validation dataset.
save_path (str): Output prefix for saved checkpoints and plots.
max_len_train (int, optional): Max number of training samples.
max_len_val (int, optional): Max number of validation samples.
patience (int): Early stopping patience.
epochs (int, optional): Number of training epochs.
learning_rate (float, optional): Override default learning rate.
confirm_train (bool): Prompt confirmation before training.
show_examples (bool): Whether to visualize intermediate results.
number_of_examples (int): Number of visualized examples.</p>
</dd>
<dt>Returns:</dt><dd><p>dict: History dictionary with loss, PSNR, SSIM per epoch.</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">history</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="s2">&quot;data/train&quot;</span><span class="p">,</span> <span class="s2">&quot;data/val&quot;</span><span class="p">,</span> <span class="n">save_path</span><span class="o">=</span><span class="s2">&quot;out/model&quot;</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.model.ModelBase.train_one_epoch">
<span class="sig-name descname"><span class="pre">train_one_epoch</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">train_dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">opt</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">e</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_examples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">number_of_examples</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_input</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_gt</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.model.ModelBase.train_one_epoch" title="Link to this definition"></a></dt>
<dd><p>Executes a single epoch of training.</p>
<p>This includes computing predictions, calculating the loss,
performing backpropagation, and updating weights.
Optionally displays and saves example outputs every few epochs.</p>
<dl>
<dt>Args:</dt><dd><p>train_dataloader (DataLoader): Training data loader.
opt (torch.optim.Optimizer): Optimizer for parameter updates.
loss (nn.Module): Loss function.
e (int): Current epoch index.
save_path (str): Base path to save example outputs.
show_examples (bool): Whether to save output examples.
number_of_examples (int): Number of examples to show.
fixed_input (Tensor): Input batch for visualization.
fixed_gt (Tensor): Ground truth batch for visualization.</p>
</dd>
<dt>Returns:</dt><dd><p>float: Total training loss accumulated during the epoch.</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">loss</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">MSELoss</span><span class="p">()</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">total_loss</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">train_one_epoch</span><span class="p">(</span><span class="n">loader</span><span class="p">,</span> <span class="n">optimizer</span><span class="p">,</span> <span class="n">loss</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;out/epoch0&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">x_fixed</span><span class="p">,</span> <span class="n">y_fixed</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.model.ModelBase.validation">
<span class="sig-name descname"><span class="pre">validation</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">val_dataloader</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">loss</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mse_fn</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">e</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.model.ModelBase.validation" title="Link to this definition"></a></dt>
<dd><p>Runs evaluation on the validation dataset.</p>
<p>Computes the total loss, PSNR, and SSIM for each batch.
Optionally uses an alternate MSE function to compute PSNR if the main loss is not MSE.</p>
<dl>
<dt>Args:</dt><dd><p>val_dataloader (DataLoader): Validation data loader.
loss (nn.Module): Loss function used in training.
mse_fn (nn.Module or None): Optional MSE function for PSNR computation.
e (int): Epoch number (for logging/progress bar).</p>
</dd>
<dt>Returns:</dt><dd><p>tuple: (total_val_loss, total_psnr, total_ssim)</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">val_loss</span><span class="p">,</span> <span class="n">psnr</span><span class="p">,</span> <span class="n">ssim</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">validation</span><span class="p">(</span><span class="n">val_loader</span><span class="p">,</span> <span class="n">loss_fn</span><span class="p">,</span> <span class="n">mse_fn</span><span class="p">,</span> <span class="n">e</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-ct_reconstruction.models.deep_back_projection">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_back_projection.DBP">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ct_reconstruction.models.deep_back_projection.</span></span><span class="sig-name descname"><span class="pre">DBP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">n_single_BP</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">i_0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accelerator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_file</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_back_projection.DBP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#ct_reconstruction.models.model.ModelBase" title="ct_reconstruction.models.model.ModelBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelBase</span></code></a></p>
<p>Deep Backprojection (DBP) network for sparse-view CT image reconstruction.</p>
<p>This model reconstructs high-quality CT images from multiple single-angle
backprojections using a deep convolutional neural network. It extends
<cite>ModelBase</cite>, inheriting functionality for training, evaluation, and configuration
management.</p>
<dl>
<dt>The architecture is composed of:</dt><dd><ul class="simple">
<li><p>One initial convolutional block (Conv2d + ReLU).</p></li>
<li><p>Fifteen intermediate convolutional blocks (Conv2d + BatchNorm2d + ReLU).</p></li>
<li><p>One final convolutional layer without activation.</p></li>
</ul>
</dd>
<dt>Args:</dt><dd><p>model_path (str): Directory path to save model checkpoints and logs.
n_single_BP (int): Number of single-angle backprojections per sample.
alpha (float): Scaling factor applied to log-transformed sinograms.
i_0 (float): Incident X-ray intensity for simulating Poisson noise.
sigma (float): Standard deviation of added Gaussian noise.
batch_size (int): Number of samples per training batch.
epochs (int): Total number of training epochs.
learning_rate (float): Learning rate for the optimizer.
debug (bool): If True, enables verbose logging and debugging output.
seed (int): Random seed for reproducibility.
accelerator (torch.device): Computation device (e.g., <cite>torch.device(“cuda”)</cite>).
scheduler (str): Learning rate scheduler name (e.g., “ReduceLROnPlateau”).
log_file (str): Path to the log file for recording training progress.</p>
</dd>
<dt>Attributes:</dt><dd><p>conv1 (nn.Sequential): Initial convolutional block.
middle_blocks (nn.ModuleList): Intermediate convolutional layers.
final (nn.Conv2d): Final convolution layer producing single-channel output.
model (nn.Sequential): Entire model as a sequential block.</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span><span class="w"> </span><span class="nn">torch</span>
<span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ct_reconstruction.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">DBP</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">DBP</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">model_path</span><span class="o">=</span><span class="s2">&quot;models/dbp&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">n_single_BP</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">i_0</span><span class="o">=</span><span class="mf">1e5</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">sigma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">debug</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">accelerator</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">scheduler</span><span class="o">=</span><span class="s2">&quot;ReduceLROnPlateau&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">log_file</span><span class="o">=</span><span class="s2">&quot;logs/dbp_training.log&quot;</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">128</span><span class="p">)</span>  <span class="c1"># input tensor</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">output</span> <span class="o">=</span> <span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>  <span class="c1"># forward pass</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">save_config</span><span class="p">()</span>  <span class="c1"># save model configuration</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_back_projection.DBP.conv_block">
<span class="sig-name descname"><span class="pre">conv_block</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_back_projection.DBP.conv_block" title="Link to this definition"></a></dt>
<dd><p>Builds an intermediate convolutional block for the DBP architecture.</p>
<dl class="simple">
<dt>This block includes:</dt><dd><ul class="simple">
<li><p>Conv2d</p></li>
<li><p>BatchNorm2d</p></li>
<li><p>ReLU activation</p></li>
</ul>
</dd>
<dt>Args:</dt><dd><p>in_channels (int): Number of input feature channels.
out_channels (int): Number of output feature channels.
kernel_size (int): Size of the convolutional kernel.
stride (int): Convolution stride.
padding (int): Zero-padding to apply.</p>
</dd>
<dt>Returns:</dt><dd><p>nn.Sequential: A sequential block with Conv2d, BatchNorm2d, and ReLU.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_back_projection.DBP.final_layer">
<span class="sig-name descname"><span class="pre">final_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_back_projection.DBP.final_layer" title="Link to this definition"></a></dt>
<dd><p>Builds the final convolutional layer that produces the output image.</p>
<p>This layer does not include an activation function.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>in_channels (int): Number of input channels.
out_channels (int): Number of output channels (typically 1).
kernel_size (int): Size of the convolutional kernel.
stride (int): Convolution stride.
padding (int): Zero-padding to apply.</p>
</dd>
<dt>Returns:</dt><dd><p>nn.Conv2d: Final convolutional layer.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_back_projection.DBP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_back_projection.DBP.forward" title="Link to this definition"></a></dt>
<dd><p>Defines the forward pass of the DBP network.</p>
<dl class="simple">
<dt>The input is passed sequentially through:</dt><dd><ul class="simple">
<li><p>Initial convolutional block</p></li>
<li><p>Fifteen intermediate convolutional blocks</p></li>
<li><p>Final convolutional layer</p></li>
</ul>
</dd>
<dt>Args:</dt><dd><dl class="simple">
<dt>x (torch.Tensor): Input tensor of shape (B, C, H, W), where:</dt><dd><p>B = batch size,
C = number of backprojection channels (<cite>n_single_BP</cite>),
H, W = spatial dimensions.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>torch.Tensor: Output tensor of shape (B, 1, H, W), representing the reconstructed image.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_back_projection.DBP.initial_layer">
<span class="sig-name descname"><span class="pre">initial_layer</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">out_channels</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">kernel_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">stride</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">padding</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_back_projection.DBP.initial_layer" title="Link to this definition"></a></dt>
<dd><p>Builds the initial convolutional block of the network.</p>
<dl class="simple">
<dt>This block consists of:</dt><dd><ul class="simple">
<li><p>Conv2d</p></li>
<li><p>ReLU activation</p></li>
</ul>
</dd>
<dt>Args:</dt><dd><p>in_channels (int): Number of input channels.
out_channels (int): Number of output channels.
kernel_size (int): Size of the convolutional kernel.
stride (int): Convolution stride.
padding (int): Zero-padding to add to each side.</p>
</dd>
<dt>Returns:</dt><dd><p>nn.Sequential: A sequential block with Conv2d and ReLU.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_back_projection.DBP.save_config">
<span class="sig-name descname"><span class="pre">save_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_back_projection.DBP.save_config" title="Link to this definition"></a></dt>
<dd><p>Saves the model configuration and hyperparameters to a JSON file.</p>
<p>The configuration file is saved at <cite>{model_path}_config.json</cite> and includes
details such as model type, training settings, device, and logging information.</p>
</dd></dl>

</dd></dl>

<dl class="py class" id="module-ct_reconstruction.models.deep_filtered_back_projection">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_filtered_back_projection.DeepFBP">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ct_reconstruction.models.deep_filtered_back_projection.</span></span><span class="sig-name descname"><span class="pre">DeepFBP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">model_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_type</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">alpha</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">i_0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">sigma</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">debug</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">seed</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">accelerator</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scheduler</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">log_file</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_filtered_back_projection.DeepFBP" title="Link to this definition"></a></dt>
<dd><p>Bases: <a class="reference internal" href="#ct_reconstruction.models.model.ModelBase" title="ct_reconstruction.models.model.ModelBase"><code class="xref py py-class docutils literal notranslate"><span class="pre">ModelBase</span></code></a></p>
<p>Main interface for training and managing the Deep Filtered Backprojection (DeepFBP) model.</p>
<p>This class wraps the <cite>DeepFBPNetwork</cite> and provides a high-level interface for training
in structured phases, saving configurations, and controlling model behavior
across the CT reconstruction pipeline.</p>
<dl>
<dt>The DeepFBP model enhances classical Filtered Backprojection by introducing:</dt><dd><ul class="simple">
<li><p>Learnable frequency-domain filters</p></li>
<li><p>1D angular interpolation modules</p></li>
<li><p>A 2D CNN denoising stage</p></li>
</ul>
</dd>
<dt>Args:</dt><dd><p>model_path (str): Path to save model checkpoints and logs.
filter_type (str): Type of filter. Options:</p>
<blockquote>
<div><ul class="simple">
<li><p>“Filter I”: Shared filter across angles.</p></li>
<li><p>Any other string: Per-angle filters.</p></li>
</ul>
</div></blockquote>
<p>alpha (float): Log scaling factor for projection values.
i_0 (float): Incident photon intensity (used for simulating noise).
sigma (float): Gaussian noise standard deviation.
batch_size (int): Number of samples per batch.
epochs (int): Number of training epochs.
learning_rate (float): Optimizer learning rate.
debug (bool): Enable verbose debug output.
seed (int): Seed for reproducibility.
accelerator (torch.device): Device for training (e.g., <cite>torch.device(“cuda”)</cite>).
scheduler (str): Learning rate scheduler type.
log_file (str): Path to output log file.</p>
</dd>
<dt>Attributes:</dt><dd><p>model (DeepFBPNetwork): Core model instance.
current_phase (int): Current training phase (1, 2, or 3).</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="kn">from</span><span class="w"> </span><span class="nn">ct_reconstruction.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">DeepFBP</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span> <span class="o">=</span> <span class="n">DeepFBP</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">model_path</span><span class="o">=</span><span class="s2">&quot;checkpoints/deepfbp&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">filter_type</span><span class="o">=</span><span class="s2">&quot;Filter I&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">alpha</span><span class="o">=</span><span class="mf">0.001</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">i_0</span><span class="o">=</span><span class="mf">1e5</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">sigma</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">batch_size</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">epochs</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">learning_rate</span><span class="o">=</span><span class="mf">1e-3</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">debug</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">seed</span><span class="o">=</span><span class="mi">42</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">accelerator</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">),</span>
<span class="gp">... </span>    <span class="n">scheduler</span><span class="o">=</span><span class="s2">&quot;StepLR&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">log_file</span><span class="o">=</span><span class="s2">&quot;train.log&quot;</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">train_deepFBP</span><span class="p">(</span>
<span class="gp">... </span>    <span class="n">training_path</span><span class="o">=</span><span class="s2">&quot;data/train&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">validation_path</span><span class="o">=</span><span class="s2">&quot;data/val&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">save_path</span><span class="o">=</span><span class="s2">&quot;checkpoints/deepfbp&quot;</span><span class="p">,</span>
<span class="gp">... </span>    <span class="n">phase</span><span class="o">=</span><span class="mi">1</span>
<span class="gp">... </span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">model</span><span class="o">.</span><span class="n">save_config</span><span class="p">()</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_filtered_back_projection.DeepFBP.save_config">
<span class="sig-name descname"><span class="pre">save_config</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_filtered_back_projection.DeepFBP.save_config" title="Link to this definition"></a></dt>
<dd><p>Saves model hyperparameters and configuration to a JSON file.</p>
<p>The file is saved to <cite>{model_path}_config.json</cite>. It includes training parameters,
model structure, device, and logging path.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_filtered_back_projection.DeepFBP.set_training_phase">
<span class="sig-name descname"><span class="pre">set_training_phase</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">phase</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_filtered_back_projection.DeepFBP.set_training_phase" title="Link to this definition"></a></dt>
<dd><p>Set model training phase and selectively activate parts of the network.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>phase (int): Training phase (1: filter only, 2: filter + interpolation, 3: all layers).</p>
</dd>
<dt>Raises:</dt><dd><p>ValueError: If an invalid phase is specified.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_filtered_back_projection.DeepFBP.train_deepFBP">
<span class="sig-name descname"><span class="pre">train_deepFBP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">training_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">validation_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">save_path</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_len_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">max_len_val</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patience</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">10</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">epochs</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learning_rate</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">confirm_train</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">show_examples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">number_of_examples</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">phase</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_filtered_back_projection.DeepFBP.train_deepFBP" title="Link to this definition"></a></dt>
<dd><p>Trains the DeepFBP model using a specific training phase.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>training_path (str): Path to training dataset.
validation_path (str): Path to validation dataset.
save_path (str): Path to save model checkpoints.
max_len_train (int, optional): Max training samples.
max_len_val (int, optional): Max validation samples.
patience (int): Early stopping patience.
confirm_train (bool): Ask for user confirmation before training.
show_examples (bool): Show reconstructed examples during training.
number_of_examples (int): Number of examples to show.
phase (int): Training phase to activate.</p>
</dd>
<dt>Returns:</dt><dd><p>dict: Training history metrics.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_filtered_back_projection.DeepFBPNetwork">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ct_reconstruction.models.deep_filtered_back_projection.</span></span><span class="sig-name descname"><span class="pre">DeepFBPNetwork</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">num_detectors</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_angles</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">A</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">filter_type</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_filtered_back_projection.DeepFBPNetwork" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Internal model for Deep Filtered Backprojection (DeepFBP) CT reconstruction.</p>
<p>This neural network combines a learnable FBP filtering stage, interpolation blocks,
and a CNN-based denoiser to reconstruct high-quality CT images from sinograms.</p>
<dl class="simple">
<dt>Components:</dt><dd><ul class="simple">
<li><p>Learnable filter module (shared or per-angle)</p></li>
<li><p>Depthwise 1D convolutional interpolators</p></li>
<li><p>Differentiable backprojection layer</p></li>
<li><p>2D CNN denoising module</p></li>
</ul>
</dd>
<dt>Args:</dt><dd><p>num_detectors (int): Number of detectors in the CT system.
num_angles (int): Number of projection angles.
A (callable): Forward projection operator (Radon transform).
filter_type (str): Filtering strategy. Use “Filter I” for shared filtering.</p>
</dd>
<dt>Attributes:</dt><dd><p>learnable_filter (LearnableFilter): Trainable frequency-domain filter module.
interpolator_{1-3} (nn.Sequential): Depthwise 1D convolutional interpolation blocks.
interpolator_conv (nn.Conv1d): Final 1D convolutional layer for angular smoothing.
denoising_conv_1 (nn.Conv2d): Initial convolution layer for image denoising.
denoising_res_{1-3} (nn.Sequential): Intermediate residual blocks for denoising.
denoising_conv_2 (nn.Conv2d): Final convolution layer to reconstruct output image.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_filtered_back_projection.DeepFBPNetwork.denoising_residual_block">
<span class="sig-name descname"><span class="pre">denoising_residual_block</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">in_channels</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_filtered_back_projection.DeepFBPNetwork.denoising_residual_block" title="Link to this definition"></a></dt>
<dd><p>Create a residual block used in the denoising stage.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>in_channels (int): Number of input and output channels.</p>
</dd>
<dt>Returns:</dt><dd><p>torch.nn.Sequential: A 2-layer convolutional residual block.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_filtered_back_projection.DeepFBPNetwork.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_filtered_back_projection.DeepFBPNetwork.forward" title="Link to this definition"></a></dt>
<dd><p>Executes the forward pass through the DeepFBPNetwork.</p>
<dl class="simple">
<dt>The pipeline includes:</dt><dd><ul class="simple">
<li><p>Learnable filtering in the frequency domain</p></li>
<li><p>Angular interpolation using depthwise convolutions</p></li>
<li><p>Differentiable backprojection via custom operator</p></li>
<li><p>Denoising using a 2D CNN</p></li>
</ul>
</dd>
<dt>Args:</dt><dd><dl class="simple">
<dt>x (torch.Tensor): Input sinogram of shape (B, 1, A, D), where:</dt><dd><p>B = batch size,
A = number of projection angles,
D = number of detectors.</p>
</dd>
</dl>
</dd>
<dt>Returns:</dt><dd><p>torch.Tensor: Reconstructed CT image of shape (B, 1, H, W).</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_filtered_back_projection.DeepFBPNetwork.intermediate_residual_block">
<span class="sig-name descname"><span class="pre">intermediate_residual_block</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">channels</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_filtered_back_projection.DeepFBPNetwork.intermediate_residual_block" title="Link to this definition"></a></dt>
<dd><p>Create a depthwise 1D residual convolutional block for interpolation.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>channels (int): Number of input/output channels (usually equal to num_angles).</p>
</dd>
<dt>Returns:</dt><dd><p>torch.nn.Sequential: A depthwise residual block.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_filtered_back_projection.DeepFBPNetwork.ram_lak_filter">
<span class="sig-name descname"><span class="pre">ram_lak_filter</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_filtered_back_projection.DeepFBPNetwork.ram_lak_filter" title="Link to this definition"></a></dt>
<dd><p>Compute the discrete Ram-Lak filter in the spatial domain. This filter corresponds 
to the ideal ramp filter <span class="math notranslate nohighlight">\(|\omega|\)</span> in the frequency domain, commonly used in 
Filtered Back Projection (FBP) for CT reconstruction.</p>
<dl class="simple">
<dt>Returns:</dt><dd><p>torch.Tensor: Real-valued frequency domain filter of shape (num_detectors,).</p>
</dd>
<dt>Notes:</dt><dd><p>This filter is derived from:
Kak, A. C., &amp; Slaney, M. (1988). Principles of computerized tomographic imaging.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_filtered_back_projection.DifferentiableBackprojection">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ct_reconstruction.models.deep_filtered_back_projection.</span></span><span class="sig-name descname"><span class="pre">DifferentiableBackprojection</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">args</span></span></em>, <em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_filtered_back_projection.DifferentiableBackprojection" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Function</span></code></p>
<p>Differentiable wrapper for the backprojection operator.</p>
<p>Enables gradient flow through custom CT backprojection routines using PyTorch’s autograd.</p>
<dl>
<dt>Methods:</dt><dd><p>forward(x, operator): Applies backprojection using <cite>operator.T(x)</cite>.
backward(grad_output): Applies forward projection using <cite>operator(grad_output)</cite>.</p>
</dd>
<dt>Args:</dt><dd><p>x (torch.Tensor): Input tensor of shape (1, A, D).
operator (callable): Custom linear operator (e.g., TomoSipo Radon transform).</p>
</dd>
<dt>Returns:</dt><dd><p>torch.Tensor: Reconstructed image.</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">image</span> <span class="o">=</span> <span class="n">DifferentiableBackprojection</span><span class="o">.</span><span class="n">apply</span><span class="p">(</span><span class="n">sinogram</span><span class="p">,</span> <span class="n">A</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_filtered_back_projection.DifferentiableBackprojection.backward">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">backward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">grad_output</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_filtered_back_projection.DifferentiableBackprojection.backward" title="Link to this definition"></a></dt>
<dd><p>Define a formula for differentiating the operation with backward mode automatic differentiation.</p>
<p>This function is to be overridden by all subclasses.
(Defining this function is equivalent to defining the <code class="docutils literal notranslate"><span class="pre">vjp</span></code> function.)</p>
<p>It must accept a context <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx</span></code> as the first argument, followed by
as many outputs as the <a class="reference internal" href="#ct_reconstruction.models.deep_filtered_back_projection.DifferentiableBackprojection.forward" title="ct_reconstruction.models.deep_filtered_back_projection.DifferentiableBackprojection.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> returned (None will be passed in
for non tensor outputs of the forward function),
and it should return as many tensors, as there were inputs to
<a class="reference internal" href="#ct_reconstruction.models.deep_filtered_back_projection.DifferentiableBackprojection.forward" title="ct_reconstruction.models.deep_filtered_back_projection.DifferentiableBackprojection.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a>. Each argument is the gradient w.r.t the given output,
and each returned value should be the gradient w.r.t. the
corresponding input. If an input is not a Tensor or is a Tensor not
requiring grads, you can just pass None as a gradient for that input.</p>
<p>The context can be used to retrieve tensors saved during the forward
pass. It also has an attribute <code class="xref py py-attr docutils literal notranslate"><span class="pre">ctx.needs_input_grad</span></code> as a tuple
of booleans representing whether each input needs gradient. E.g.,
<a class="reference internal" href="#ct_reconstruction.models.deep_filtered_back_projection.DifferentiableBackprojection.backward" title="ct_reconstruction.models.deep_filtered_back_projection.DifferentiableBackprojection.backward"><code class="xref py py-func docutils literal notranslate"><span class="pre">backward()</span></code></a> will have <code class="docutils literal notranslate"><span class="pre">ctx.needs_input_grad[0]</span> <span class="pre">=</span> <span class="pre">True</span></code> if the
first input to <a class="reference internal" href="#ct_reconstruction.models.deep_filtered_back_projection.DifferentiableBackprojection.forward" title="ct_reconstruction.models.deep_filtered_back_projection.DifferentiableBackprojection.forward"><code class="xref py py-func docutils literal notranslate"><span class="pre">forward()</span></code></a> needs gradient computed w.r.t. the
output.</p>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_filtered_back_projection.DifferentiableBackprojection.forward">
<em class="property"><span class="pre">static</span><span class="w"> </span></em><span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ctx</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">operator</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_filtered_back_projection.DifferentiableBackprojection.forward" title="Link to this definition"></a></dt>
<dd><p>Define the forward of the custom autograd Function.</p>
<p>This function is to be overridden by all subclasses.
There are two ways to define forward:</p>
<p>Usage 1 (Combined forward and ctx):</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="n">ctx</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>
</div>
<ul class="simple">
<li><p>It must accept a context ctx as the first argument, followed by any
number of arguments (tensors or other types).</p></li>
<li><p>See <span class="xref std std-ref">combining-forward-context</span> for more details</p></li>
</ul>
<p>Usage 2 (Separate forward and ctx):</p>
<div class="highlight-python3 notranslate"><div class="highlight"><pre><span></span><span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">forward</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
    <span class="k">pass</span>

<span class="nd">@staticmethod</span>
<span class="k">def</span><span class="w"> </span><span class="nf">setup_context</span><span class="p">(</span><span class="n">ctx</span><span class="p">:</span> <span class="n">Any</span><span class="p">,</span> <span class="n">inputs</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">Any</span><span class="p">,</span> <span class="o">...</span><span class="p">],</span> <span class="n">output</span><span class="p">:</span> <span class="n">Any</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">pass</span>
</pre></div>
</div>
<ul class="simple">
<li><p>The forward no longer accepts a ctx argument.</p></li>
<li><p>Instead, you must also override the <code class="xref py py-meth docutils literal notranslate"><span class="pre">torch.autograd.Function.setup_context()</span></code>
staticmethod to handle setting up the <code class="docutils literal notranslate"><span class="pre">ctx</span></code> object.
<code class="docutils literal notranslate"><span class="pre">output</span></code> is the output of the forward, <code class="docutils literal notranslate"><span class="pre">inputs</span></code> are a Tuple of inputs
to the forward.</p></li>
<li><p>See <span class="xref std std-ref">extending-autograd</span> for more details</p></li>
</ul>
<p>The context can be used to store arbitrary data that can be then
retrieved during the backward pass. Tensors should not be stored
directly on <cite>ctx</cite> (though this is not currently enforced for
backward compatibility). Instead, tensors should be saved either with
<code class="xref py py-func docutils literal notranslate"><span class="pre">ctx.save_for_backward()</span></code> if they are intended to be used in
<code class="docutils literal notranslate"><span class="pre">backward</span></code> (equivalently, <code class="docutils literal notranslate"><span class="pre">vjp</span></code>) or <code class="xref py py-func docutils literal notranslate"><span class="pre">ctx.save_for_forward()</span></code>
if they are intended to be used for in <code class="docutils literal notranslate"><span class="pre">jvp</span></code>.</p>
</dd></dl>

</dd></dl>

<dl class="py class">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_filtered_back_projection.LearnableFilter">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">ct_reconstruction.models.deep_filtered_back_projection.</span></span><span class="sig-name descname"><span class="pre">LearnableFilter</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">init_filter</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">per_angle</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_angles</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_filtered_back_projection.LearnableFilter" title="Link to this definition"></a></dt>
<dd><p>Bases: <code class="xref py py-class docutils literal notranslate"><span class="pre">Module</span></code></p>
<p>Learnable frequency-domain filter module for CT sinograms.</p>
<p>This module replaces traditional analytical filters (e.g., Ram-Lak)
with trainable parameters. Can operate in shared or per-angle mode.</p>
<dl class="simple">
<dt>Args:</dt><dd><p>init_filter (torch.Tensor): Initial frequency-domain filter (1D).
per_angle (bool): If True, create one filter per projection angle.
num_angles (int, optional): Required if <cite>per_angle=True</cite>.</p>
</dd>
<dt>Attributes:</dt><dd><p>weights (nn.Parameter): Filter weights in the frequency domain.</p>
</dd>
<dt>Raises:</dt><dd><p>AssertionError: If <cite>per_angle=True</cite> and <cite>num_angles</cite> is not provided.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="ct_reconstruction.models.deep_filtered_back_projection.LearnableFilter.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="headerlink" href="#ct_reconstruction.models.deep_filtered_back_projection.LearnableFilter.forward" title="Link to this definition"></a></dt>
<dd><p>Apply the learnable frequency-domain filter to the input sinogram.</p>
<dl>
<dt>Args:</dt><dd><p>x (torch.Tensor): Input sinogram of shape (B, A, D).</p>
</dd>
<dt>Returns:</dt><dd><p>torch.Tensor: Filtered sinogram of same shape.</p>
</dd>
<dt>Example:</dt><dd><div class="doctest highlight-default notranslate"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">filtered</span> <span class="o">=</span> <span class="n">filter_module</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</pre></div>
</div>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="datasets.html" class="btn btn-neutral float-left" title="LoDoPaBDataset Class" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="utils.html" class="btn btn-neutral float-right" title="Utility Functions for CT Reconstruction" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Andrea Sainz Bear.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>